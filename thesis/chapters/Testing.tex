\chapter{Testing purposes and pipeline}
\label{chapter:testing}

%practical computation: runtime
%behaviour on actual meshes: topology changes, isometry, scaling, holes

In order to get a grasp of the properties and the behavior of the different distances, we ran a set of experiments on a set of meshes from the datasets TOSCA \cite{bronstein2008numerical}, SHREC 2010 \cite{bronstein2010shrec} and SHREC 2011 \cite{dutagaci2011shrec}.
These datasets contain triangulated meshes, undergoing different transformations, ranging from scaling through holes in the mesh to noise and topology changes.
These shapes will allow us to get a understanding of the performance of the four different metrics if subjected to these kind of transformations.

\section{Timing}

The first experiment we ran was to compare how long it took the different metric to compute the distances between points, a task not uncommon in shape analysis applications.
In order to do so, we are using Matlab on a 2.40GHz Intel Core 2 Duo processor.
We timed computation of distances on meshes with varying amounts of vertices between all points.
To keep the computation times within a reasonable range, we approximated the exact geodesic distance by the Dijkstra algorithm on the larger meshes.

In a second experiment, we are computing the distances between pairs of points of a set $N$ of the size $2,10,100,500$.
Additionally, in this experiment we take a deeper look at the computations which can be done beforehand.
The computation of the distances based on the Laplacians eigenfunctions can be speeded up by precalculating them and then using them for each other computation step, making the overall computation-time shorter.
Notice however that there cannot be any time saving steps taken for the geodesic distance, at least not with the method described in chapter~\ref{section:geodesic}.
As a side note, an alternative approach, which approximates the geodesic distance by using the heat diffusion process based on the Laplacian, was proposed in \cite{crane2013geodesics}.

\section{Sensitivity to noise, tessellation and deformation}
To test the robustness of the metric functions, we compute the distance function for different kinds of changes of the original surface.
We then compare the result visually by correlating the color and the shape of the isolines of the original mesh and the changed one.
As the SHREC datasets provide different strengths of modifications in a multitude of areas, we will depict those showing the clearest result to make a point in the resulting figure.
To be specific, the different deformations we will take into account are:
\begin{itemize}
	\item isometry: The surface undergoes a isometric transformation, for example if the mesh of a person is changed to have a different pose.
	\item affine: If an affine transformation is applied, this can change the rotation, the scale and shear the mesh while retaining collinearity, parallelism and the ratios of distances between collinear points.
	\item changes in local/global scale: These changes include the shrinking and growing in size of parts of the mesh or the whole mesh.
	\item micro holes/holes: Results in not watertight meshes whose topology has holes of varying sizes.
	\item noise/shot noise: Here, different amounts of noise is added to the vertex coordinates of parts of the mesh/ the whole mesh.
	\item topology/rasterize: Summarizes changes which change the topology of a mesh like a different tessellation of the surface or  additional edges or faces.
	\item partial: Only parts of the mesh are given, with no further information about the whole mesh.
%TODO?	\item sampling: %possibly include: relabel der punkte (+ isometry vllt) 2011 different poses = isometry
\end{itemize}

%fps commonly used -> test it with the different metrics
%TODO citation for fps
In the next experiment we will watch the behavior of the different metrics, if they are used to obtain a farthest point sampling, FPS for short, of a given mesh.
The idea behind the FPS is that meshes can get quite complex with huge amounts of vertices, slowing down the computations on the mesh.
%TODO? reference back to open ball sampling in shapespaces?
The FPS provides a fast and practical way to obtain an almost optimal approximation of an open ball covering if it is given a metric on the mesh.
The way it works is to start from a random vertex or with the two vertices farthest away from each other and then, with each iteration step, add the vertex which is farthest away from the currently selected to the set.
The resulting set is in general not unique but can then be used to assign all vertices to vertices of the set, representing them and resulting in a so called Voronoi sampling.
The obtained FPS and the Voronoi sampling can then be used to save computation time on tasks like shape matching, so the usage of the FPS is a common procedure in shape analysis.
During the experiments, we will compare the FPS of 100 points  of the original shape with the FPS of shapes with the above mentioned changes and how good the set covers the mesh.
In this experiment one additional metric will be used:
The Euclidean distance is not isometry invariant, which makes it not fitting to use for shape matching in general, but it is known to produce good results if used in the FPS.
