\chapter{Differential Geometry}
\label{chapter:differentialGeometry}

\section{Regular Surfaces and the First Fundamental Form}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%%     section regular surface
%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Since all of the metrics in this thesis are based on the fact, that meshes can be approximated by regular surfaces, this section will give some insight into the basics of the math behind them.
To begin with, we narrow down our choice of meshes to those, which are 2-dimensional manifolds without a boundary, so that we do not have to worry about boundary conditions.
But how can a complex mesh be represented mathmatically?
The intuitive answer to that is to take pieces of a plane and to deform and arrange them, such that they cover the whole surface.
The only constraints to ensure the ability to apply differental geometry are, that the resulting surface is not allowed to have sharp points/edges or self-intersections.
A more rigorous definition is the following:
\begin{mydef}[regular surface]
	A subset $S \subset \real^3$ is a regular surface if, for each $p \in S$, there exists a neighborhood $V \in \real^3$ and a map $x:U \rightarrow V \cap S$ of an open set $U \subset \real^2$ onto $V \cap S \subset \real^3$ such that:
	\begin{enumerate}
		\item $x$ is differentiable. That means that if we write
			$$x(u,v) = (\mathbf{x}(u,v), \mathbf{y}(u,v), \mathbf{z}(u,v)), \quad (u,v) \in U,$$
			the functions $\mathbf{x}(u,v), \mathbf{y}(u,v), \mathbf{z}(u,v)$ have continuous partial derivatives of all orders in $U$.
		\item x is a homeomorphism. Since $x$ is continuous by condition 1, this means that $x$ has an inverse $x^{-1}: V \cap S \rightarrow U$ which is continuous.
		\item For each $q \in U$, the differential $dx_q: \real^2 \rightarrow \real^3$ has full rank.
	\end{enumerate}
\end{mydef}
%%TODO figure showing regular surface
This definition states, that for every point on the surface there exists a neighborhood with a map $x$ wich maps from the parameter domain $U \subset \real^2$ to $S$ (in correspondance to the plane patch from earlier) and the collection of all those neighborhoods defines the regular parametrized surface.
\begin{remark}
	The first condition ensures that we can use differential geometry on the regular surface, while the second one restricts the surface, such that it can not have intersections with itself.
	Even though the differential of the map $dx_p$ is covered later in this section, it can already be told that the third condition is responsible for the surface only having non-degenerated tangent planes.
\end{remark}

One of the important points of regular surfaces is, that its local poperties do not change, if we use another parametrization.
Thankfully, it has already been proven, that there always exists a diffeomorphism that can tansfer points from one parameter domain to the other and therefore make different maps interchangeable:
%%TODO remark/proposition/thesis?
Let $p$ be a point on a regular surface $S$ and $x: U \rightarrow S$ and $y: V \rightarrow S$ be parametrizations of $S$ with $p \in x(U) \cap y(V) = W$.
Then the change of coordinates $h: y^{-1}(W) \rightarrow x^{-1}(W), h = x^{-1} \circ y$ is differentiable and has a differentiable inverse.
%%TODO \cite{do1976differential}[70ff]

Now that we have defined regular surfaces, the next step is to find a way to express functions defined on the surface.
Since we already know, that a regular surface is just a image of a two dimensional parameter domain, we can use that knowledge to define our function there.
\begin{mydef}[differentiable function on surfaces]
	Let $f$ be a function from an open subset $V \subset S$ of a surface $S$ to $\real$.
	Then $f$ is called differentiable at $p \in V$ if, for a parametrization $x: U \rightarrow S, p \in x(U) \subset V$, the composition $\tilde{f} = f \circ x$ is differentiable at $x^{-1}(p)$.
	$f$ is differentiable in V, if it is differentiable at all points of $V$.
\end{mydef}
%%TODO \cite{do1976differential}[72ff]
This means we can now transfer functions from one domain into the other, given a parametrization.

%%tangent planes
After defining how to transcribe functions between the parameter domain and the actual surface, we will now continue with the behaviour of vectors under the differential map $x$.
Let us begin with the best visual concept of differentiating a map, the tangent plane.
The concept of a tangent plane is that at a certain point on the surface, the tangent vectors of all differntiable parametrized curves through that point constitute a plane.
\begin{mydef}[tangent plane]
	Let $x: U  \subset \real^2 \rightarrow S$ be a parametrization of a regular surface $S$ and let $q \in U$.
	The vector subspace of dimension 2, $dx_q(\real^2) \subset \real^3,$ coincides with the set of tangent vectors to $S$ at $x(q)$ and is called tangent plane to $S$ at $p = x(q)$ and will be denoted by $T_p(S)$.
\end{mydef}
Notice, that the above definition of the tangent plane is not dependent on the parametrization $x$.
The parametrization only determines the basis ${(\partial x/\partial u)(q), (\partial x/\partial v)(q)}$ of the tangent plane $T_pS$.
From here on out, they are abbreviated as $(\partial x/\partial u) = x_u$ and $(\partial x/\partial v) = x_v$.
Before we take a look at vectors specifically, we have to understand the concept of the differential of a map which was already used a few times in this thesis:
\begin{mydef}[differential of a map]
	Let $x: U \rightarrow S$ be a differential map and let $\alpha: (-\epsilon, \epsilon) \rightarrow U$ be a differential curve in the parameter domain with $\alpha(0) = q, \alpha'(0) = w$.
	The composition of them is called $\beta = x \circ \alpha$.
	Then the differential of $x$ at $q$ is
	$$dx_q(w) = \beta'(0).$$
\end{mydef}
Since $\beta$ is the image of $\alpha$ on the surface $S$, $dx_q$ maps tangent vectors from the parameter domain to tangent vectors of the surface by definition.
Also, $dx_q$ is not dependent on $\alpha$ but is solely a property of the differential map $x$ and it is a linear map.
This can be seen, if we apply the chain rule to the definition of $dx_q$ where $(u,v)$ are coordinates in $U$ and $(x,y,z)$ are coordinates in $\real^3$:
$$dx_q(w) = \beta'(0) = (x \circ \alpha)'(0) = x'(\alpha(0)) \cdot \alpha'(0) = \begin{pmatrix} \partial(x)/\partial(u) & \partial(x)/\partial(v) \\
																								\partial(y)/\partial(u) & \partial(y)/\partial(v) \\
																								\partial(z)/\partial(u) & \partial(z)/\partial(v)
																				\end{pmatrix}
	\begin{pmatrix} \partial u/\partial t \\ \partial v /\partial t \end{pmatrix} $$
Notice that the first matrix indeed does not depend on a specific $\alpha$.

%% first fundamental form
The last point in this section is the introduction of the first fundamental form, which is a replacement for the natural inner product on a surface $S$.
\begin{mydef}[first fundamental form]
	The quadratic form $I_p : T_q(s) \rightarrow \real$ on $T_q(S)$, defined by
	$$I_p(w) =  \langle w,w\rangle_p = |w|^2 > 0,$$
	is called the first fundamental form of the regular surface $S\subset\real^3$ at $p\in S$.
\end{mydef}
%%TODO \cite{do1976differential}[92] for two paragraphs
It can be used to determine geometric values like lengths of curves and areas of regions on regular surfaces without referring back to the ambient space..

Given a certain basis ${x_u, x_v}$ associated to a parametrization $x(u,v)$ at $p$, we can express the first fundamental form in that basis.
Since a tangent vector $w\in T_p(S)$ is the tangent vector to a parametrized curve $\alpha(t) = x(u(t),v(t)), t\in (-\epsilon,\epsilon)$, with $p = \alpha(0) = x(u_0,v_0)$, we obtain
\begin{align*}
	I_p(\alpha'(0)) &= \langle \alpha'(0),\alpha'(0)\rangle_p \\
					&= \langle x_u u' + x_v v',x_u u' + x_v v' \rangle_p \\
					&= \langle x_u ,x_u \rangle_p  (u')^2 + 2\langle x_u ,x_v \rangle_p u' v' + \langle x_v ,x_v \rangle_p (v')^2 \\
					&= E(u')^2 + 2Fu'v'+G(v')^2 \\
					&= \begin{pmatrix} u' & v' \end{pmatrix} \begin{pmatrix} E & F \\ F & G \end{pmatrix} \begin{pmatrix}u' \\ v'\end{pmatrix}
\end{align*}
where the values of the functions involved are computed for $t = 0$ and $E$,$F$ and $G$ are dependent on the basis ${x_u,x_v}$ of $T_p(S)$.
By letting p run in the coordinate neighborhood corresponding to $x(u,v)$ we obtain functions $E(u,v)$,$F(u,v)$ and $G(u,v)$ wicht are differentiable in that neighborhood.
These coefficients play important roles in many intrinsic properties of the surface.
Now we can even use two different vectors $(\alpha,\beta), (\delta,\gamma) \in T_pS$ to insert into the matrix notation to get the more general bilinear form of the first fundamental form:
$$I_p((\alpha, \beta),(\delta, \gamma)) = \begin{pmatrix} \alpha & \beta \end{pmatrix} \begin{pmatrix} E & F \\ F & G \end{pmatrix} \begin{pmatrix}\delta \\ \gamma\end{pmatrix}$$
One nice property of the first fundamental form is that it is invariant to isometries, which makes it a good candidate for a base of an intrinsic metric.

\section{Minimal Geodesics on Surfaces}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%%     section geodesics
%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
One of the most fundamental metrics is the idea of constructing the shortest path between two points and define the length of that path as the distance between those two points.
In the euclidean domain, this metric is defined by the euclidean norm of the vector joining the two points.
On a regular surface, defining this distance is not as easy, since a lower dimensional set is embedded into a higher dimension.
The basic idea is, to find the shortest path along the surface from one point to the other and take its length as the distance.
It is commonly known, that such a path is a straight line and its generalisation to curved surfaces is called a minimal geodesic, which will be defined during the course of this section.

Since a geodesic is definitly some kind of curve, we start by introducing the core concepts needed for the definition of a geodesic.
\begin{mydef}[parametrized curve]
	A parametrized curve $\alpha$ is the restriction of a differentiable mapping $( 0-\epsilon, l+\epsilon) \rightarrow S), \epsilon > 0$ to the intervall $[0,l]$.
	The curve $\alpha$ is called to join two points $p,q \in S$ if and only if $\alpha(0) = p$ and $\alpha(l) = q$ and it is called regular, if its derivative $\alpha'(t)$ is nonzero for $t \in [0,l]$.
\end{mydef}
Now let $w(t)$ be a vectorfield along the curve $\alpha$.
Then $w$ is called differentiable, if for the parametization $x(u,v)$ the vector field $w(t)$ can be written as $w(t) = a(t) \cdot x_u + b(t) \cdot x_v$, where $a$ and $b$ are differentiable functions.
Another important part is the covariant derivative of a vectorfield.
\begin{mydef}[covariant derivative]
	Let $\alpha(t)$ be a parametrized curve on $S$ with $\alpha(0) = p \in S, \alpha'(0) = y \in T_pS$ and a differential vector field $w(t)$ constricted to $\alpha$.
	The normal projection of the derivative of $w$ in respect to time $\frac{dw}{dt}(0)$ onto the tangent space $T_pS$ is called the covariant derivative at $p$ of the vector field $w$ relative to $y$:$\frac{Dw}{dt}(0)$
\end{mydef}
The covariant derivative is well-defined for differentiable vectorfields and is furthermore intrinsic.
This can be seen, if we look at the expression for the covariant derivative:
$$\frac{Dw}{dt} = (a' + \Gamma^{1}_{1 1} a u' + \Gamma^{1}_{1 2} a v' + \Gamma^{1}_{1 2} b u' + \Gamma^{1}_{2 2} b v')x_u + (b' + \Gamma^{2}_{1 1} a u' + \Gamma^{2}_{1 2} a v' + \Gamma^{2}_{1 2} b u' + \Gamma^{2}_{2 2} b v')x_v$$
where $(u' v') = y$  and the $\Gamma$ are the so called Christoffel symbols, which are only dependent on first fundamental form and therefore $\frac{Dw}{dt}$ is an intrinsic property of the suface as shown in chapter 4.3 of \cite{do1976differential}.
A geometric interpretation of the covariant derivative would be the second derivative of the vectorfield $w$ as seen from the surface.
\begin{mydef}[parallel vectorfield]
	The vectorfield $w$ along the parametrized curve $\alpha$ is called parallel if it satisfies
	$$\frac{Dw}{dt} = 0 $$
	for all points on $\alpha$.
\end{mydef}

%% picture
Now every aspect of the following definition has been introduced:
\begin{mydef}[geodesic curve]
	A nonconstant, parametrized curve $\gamma: I \rightarrow S$ is called geodesic at $t \in I$ if the field of its tangentvectors $\gamma'(t)$ is parallel along $\gamma$ at $t$.
	Consequently, the curve $\gamma$ is called geodesic, if $\frac{D\gamma'}{dt} = 0 \forall t \in I$.
\end{mydef}
\cite[238-246]{do1976differential}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% TODO example?
If we look at a sphere $S^2$, its geodesic curves are obtained by intersecting the sphere with a plane passing through the centerpoint of the sphere.
So there are at least two geodesics joining two points $p_1$ and $p_2$, just by following the intersection into different directions, starting from $p_1$.
																							%%% noch zu erklären %%%%TODO
To be a minimal geodesic, the curves length has to be less or equal to the length of any other piecewise regular curve on the surface.
On the $S^2$ this would be the shorter arc joining $p_1$ and $p_2$ or, if they are antipodal points like the north and the south pole, there is an infinite number of minimal geodesics joining $p_1$ and $p_2$.
On the other hand, the existance of a minimal geodesic is not granted:
Let $p$ be a point on the minimal geodesic joining the points $p_1$ and $p_2$ (which are not a pair of antipodal points/sufficiently close) on the sphere $S^2$ and let the surface be $S^2-{p}$.
Then there exists no minimal geodesic between $p_1$ and $p_2$, since the only other geodesic joining them goes the long way around and is therefore longer than a piecewise regular curve almost equal to the minimal geodesic on $S^2$ except for going around the hole at $p$.
%%TODO picture?
One way to ensure the existance of a minimal geodesic is to constrain the surfaces to have certain properties.
%5.3 -P5 every compact surface is complete -> compact (closed and bounded [not inf]112 im text) also
%complete?
In general, most of the surfaces examined are both closed and bounded wich means, they are compact.
As shown in \cite[331-332]{do1976differential}, compact surfaces are complete and we can use the theorem of Hopf and Rinow: \\
\begin{theorem}
	``Let S be a complete surface. Given two points $p,q$, there exists a minimal geodesic joining $p$ and $q$.'' \cite[333]{do1976differential} \\
\end{theorem}
Hence we can safely assume that there exists a minimal geodesic on the regular surfaces considered.
This approach is not very practical on actual meshes, since it needs a parametrisation of the surface and comparing the length of all possible geodesic curves is not practical.

\subsection*{Discretisation to triangulated meshes}
There are two main ways to compute shortest geodesic paths on triangulated meshes: One is solving the Eikonal equation with the Fast Marching Method to aproximate geodesics on the mesh.
The second way, which will be used later in this paper, has been proposed by Mitchel, Mount and Papadimitriou (MMP) in 1987.
Their basic ideas are presented here, for further information, you can refer back to \cite{surazhsky2005fast}.
The fundamental idea is to use a simple parametrisation of the geodesic distance on each edge and propagate the distance information starting from the source point over the whole surface.
Take note, that geodesics on a triangular mesh need to have two properties:
\begin{itemize}
	\item They need to be straigth lines within each face.
	\item When crossing over an edge, the shortest paths need to correspond to a straight line if the faces are unfolded into a common plane.
\end{itemize}
Additionally, there are two kinds of vertices which need additional attention: boundary vertices and saddle vertices, which have a total angle greater than $2\pi$.
With this in mind, we can take a look at the MMP algorithm.
The main element of this are the so called windows, which bundle multiple shortest paths that traverse an edge into the same direction, into one tuple of six parameters.
%% need pictures of the different parameters + small picture for pseudo sources+distances

\paragraph{The window parameters}
\begin{figure}[h]
	\centering
	\includegraphics[width = 0.9\textwidth]{pictures/geodesics_parameters}
	\caption{Visualization of the window parameters}
	\label{fig:geo_param}
\end{figure}
Let's first assume, that the shortest path from the source vertex $v_s$ to the point $p$ does not pass through any boundary or saddle vertices.
In that case, all traversed triangles can be unfolded into a common plane, so that the path is a straight line in that plane.
If we now consider some neighboring points of $p$ whose shortest paths pass through the same sequence of faces, we get at set of straight lines emanating from $v_s$ intersecting the same edges.
So these paths are combined into one window and it is saved for the edge $e$ by first defining its width through determining the beginning and the end point of the window by $b_0, b_1 \in [0,||e||]$.
Additionally, the relative position of the source vertex to the window is encoded by the distance $d_0,d_1$ to the two window endpoints and a binary direction $\tau$.
In the case, that the path passes through one or more saddle/boundary vertices, let $s$ be the one closest to $p$.
All paths of $p$ and its neighboring points pass through $s$, which therefore is a (pseudo-)source for them.
The window now stores the distance information to $s$ as its source and an additional parameter that contains the distance of $s$ from $v_s$: $\sigma = D(s)$.
So the distance field $D$ over the window is described by the tuple $(b_0,b_1,d_0,d_1,\sigma,\tau)$.

\paragraph{Window propagation}
\begin{figure}[h]
	\centering
	\includegraphics[width = 0.9\textwidth]{pictures/geodesics_new_windows}
	\caption{Visualization of the three possible situations during the propatation step.}
	\label{fig:geo_new_windows}
\end{figure}
%% pictures of the propagation process (1,2,4 new windows)
To compute the distance function over the whole mesh, the windows are propagated over it.
Given a window $w$ on the edge $e_1$, the distance field will be propagated over a adjacent face $f$, resulting in new windows on the opposing edges $e_2,e_3$ of that face.
Since there are possibly already existing windows on those edges, we later need to intersect them with the existing ones and only keep the information of the shortest distances.
After again unfolding the mesh into a common plane, we extend the connections of the endpoints of $w$ and the source $s$ until they intersect with one of the opposing edges.
This results in either one or two new windows, depending if there is an vertex in between the two intersection points.
Now we already have the values of $ b_0', b_1'$ of the new window and only need to compute the new distances to the endpoints $d_0',d_1'$.
The pseudosource distance $\sigma' = \sigma$ stays the same and the direction $\tau$ is assigned to point into the face $f$.

The special case of $w$ being adjacent to a saddle/boundary vertex $v$ results in a few additional windows.
Since shortest paths may pass through $v$, we need to add windows to the parts of the face, which can be reached through $v$ and is not already taken care of by the preceding steps.
%% todo more about this, once i have an illustration

\paragraph{Intersection of windows}
\begin{figure}[h]
	\centering
	\includegraphics[width = 0.9\textwidth]{pictures/geodesics_intersection}
	\caption{Left: initial situation before the intersection. Right: the starting and ending points of the two windows have been adjusted to the point $p$}
	\label{fig:geo_intersect}
\end{figure}
Once all new windows were created, we can intersect them with the existing ones, resulting in windows with the minimal distance.
Let $\delta$ be the non-empty intersection interval of two windows $w_1$ and $w_2$.
In the simple case, that one of the windows has a larger distance all over $\delta$, then $\delta$ is just cut away from its interval.
This leaves only intersections, were one window has a shorter distance on one end, while the other window is nearer to the source on the other end.
To intersect those two windows, we need to find the point $p \in \delta$  in between them, which is exactly as far away from the source in one window, as it is in the other.
This means, that $p$ has to fullfill the following condition:
$$||s_0 - p|| + \sigma_0 = ||s_1 - p|| + \sigma_1$$
This equation can be reduced to a quadric which has only one solution with the constraint $p \in \delta$.
%% TODO exact formula?
Finally, we only need to adjust the boundarys $b_1$ of $w_1$ and $b_0$ of $w_2$ to match the point $p$ and recompute the endpoint distances.

\paragraph{Propagation order}
The described algorithm propagates the distance information from the source point outwards in a Dijkstra-like manner.
This means, that every time, a window is created or modified, it will be placed in a priority queue from which then the first window is taken and propagated across a face next.
Even though the algorithm computes the same result even without an specific ordering of the queue, the performance is increased, if the queue is ordered by the windows distance from the source.
Notice, that windows can be added, modified and removed in one step and the queue has to be updated accordingly.

During initialization, on each edge adjacent to the source vertex $v_s$ a window is created.
The distance fields on those windows are trivial, e.g. the distance every vertex adjacent to $v_s$ is equal to the edge length.
After that, one window is popped of the priority queue in each step and processed.

\paragraph{Construction of geodesic paths}
After the distance information was propagated throughout the whole mesh, it is easy to find the shortest/geodesic path from any given point $p$ to the source $s$.
In the most general case of $p$ lying on the interior of a face, we first collect all the windows on its edges and minimize the length of the path going from $p$ through the window to the source.
So in other words, we minimize $||p - p'|| + D(p')$ for all p' within those windows.

The next step is to trace back the path from $p'$ to $s$.
To do this, we take the direction $\tau$ of the window containing $p'$ and locate its pseudo-source $v_s$ using the distance information provided.
The next point in the backtracing process is obtained by intersecting the line $\overline{v_{s}p'}$ with the opposite edges of the face.
Now the algorithm is repeated with the window containing the intersection.

A special case are boundary or saddle vertices again:
%%TODO probably every time, i reach a pseudosource itself
To trace them back, we look at the adjacent windows and iteratively go through them, until we find one with a pseudosource different from the boundary/saddle vertex we are currently looking at.

\cite{surazhsky2005fast}


\section{The Laplacian and Metrics based on its Eigenfunctions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%%     section Laplacian
%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%laplacian is linear -> can be represented as a matrix
\subsection{The Laplacian}
\subsubsection{Definition}
\subsubsection{Eigenfunctions}
\subsection{The Biharmonic Distance}
\subsection{The Diffusion Distance}
\subsection{Commute-time Distance}
